{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_initial_params(dictionary, param_name, domain_array):\n",
    "    if param_name in dictionary and bool(dictionary[param_name]):\n",
    "        params_array = dictionary[param_name]\n",
    "    else:\n",
    "        params_array = domain_array\n",
    "    return params_array\n",
    "\n",
    "\n",
    "# each value in dict passed to GridSearchCV must be array, like {'n_estimators': [100], 'learning_rate' : [0.01]}\n",
    "# but the same value provided to model must be int/str: {'n_estimators': 100, 'learning_rate' : 0.01}\n",
    "# the function below converts dictwith arrays to dict with integers\n",
    "def convert_dict_of_arrays(dictionary):\n",
    "    ret = {}\n",
    "    for key, value_arr in dictionary.items():\n",
    "        ret[key] = value_arr[0]\n",
    "    return ret\n",
    "\n",
    "\n",
    "# update parameter values by those returned by Gridsearch\n",
    "def update_model_params(model, model_params, params_to_update):\n",
    "    try:\n",
    "        model_params.update(params_to_update)\n",
    "        model = model.__class__(**model_params)\n",
    "    except:\n",
    "        pass\n",
    "    return model\n",
    "\n",
    "\n",
    "# create new array of parameters, which will be further researched to find optimap param values\n",
    "def create_new_array(param_name, param_array, position, param_requirments):\n",
    "    if position == 0:\n",
    "        lowest_val = param_array[position] * 2 - param_array[position + 1]\n",
    "        # check formal value requirements\n",
    "        if lowest_val < param_requirments[param_name]['min']:\n",
    "            lowest_val = param_requirments[param_name]['min']\n",
    "        new_array = [lowest_val, param_array[position], ((param_array[position + 1] + param_array[position]) / 2)]\n",
    "    # if optimal value was the last in array - take higher values\n",
    "    elif param_array[-1] == param_array[position]:\n",
    "        highest_val = param_array[position] * 2 + param_array[position - 1]\n",
    "        # check formal value requirements\n",
    "        if highest_val > param_requirments[param_name]['max']:\n",
    "            highest_val = param_requirments[param_name]['max']\n",
    "        new_array = [((param_array[position - 1] + param_array[position]) / 2), param_array[position], highest_val]\n",
    "    else:\n",
    "        new_array = [((param_array[position - 1] + param_array[position]) / 2), param_array[position], ((param_array[position + 1] + param_array[position]) / 2)]\n",
    "\n",
    "    # check data type requirements\n",
    "    if param_requirments[param_name]['type'] == 'int':\n",
    "        new_array[0] = math.ceil(new_array[0])\n",
    "        new_array[-1] = math.floor(new_array[-1])\n",
    "        new_array[1:-1] = np.round(new_array[1:-1])\n",
    "    # remove duplicates:\n",
    "    new_array = np.unique(new_array)\n",
    "    return new_array\n",
    "\n",
    "\n",
    "# perform Gridsearch over parameters and return the best model\n",
    "def find_best_params(model, parameters, X_train, y_train, min_loss, scoring, n_folds, iid, max_fea, initial_score=0):\n",
    "    param_requirments = {'subsample': {'max': 1, 'min': 1 / len(X_train), 'type': 'float'},  # minimal value is fraction for one row\n",
    "                         'colsample_bytree': {'max': 1, 'min': 1 / X_train.shape[1], 'type': 'float'},  # # minimal value is fraction for one column\n",
    "                         'reg_alpha': {'max': np.inf, 'min': 0, 'type': 'float'},\n",
    "                         'reg_lambda': {'max': np.inf, 'min': 0, 'type': 'float'},\n",
    "                         'reg_scale_pos_weightlambda': {'max': np.inf, 'min': 0, 'type': 'float'},\n",
    "                         'learning_rate': {'max': 1, 'min': 1e-15, 'type': 'float'},  # technically it moght be more than 1, but it may lead to underfittting\n",
    "                         'n_estimators': {'max': np.inf, 'min': 1, 'type': 'int'},\n",
    "                         'max_features': {'max': max_fea, 'min': 1, 'type': 'int'},\n",
    "                         'gamma': {'max': np.inf, 'min': 0, 'type': 'float'},\n",
    "                         'min_samples_leaf': {'max': np.inf, 'min': 5, 'type': 'int'},\n",
    "                         # could be float (then i'ts percentage of all examples, but we'll use integers (number of samples) for consistency)\n",
    "                         'min_samples_split': {'max': np.inf, 'min': 5, 'type': 'int'},\n",
    "                         # could be float (then i'ts percentage of all examples, but we'll use integers (number of samples) for consistency)\n",
    "                         'min_child_samples': {'max': np.inf, 'min': 5, 'type': 'int'},\n",
    "                         'min_split_gain': {'max': np.inf, 'min': 0, 'type': 'float'},\n",
    "                         'min_child_weight': {'max': np.inf, 'min': 0, 'type': 'float'},\n",
    "                         'max_depth': {'max': np.inf, 'min': 1, 'type': 'int'},\n",
    "                         'num_leaves': {'max': np.inf, 'min': 2, 'type': 'int'}}\n",
    "\n",
    "    assert (min_loss != 0)  # if equal to 0 - would be calculated infinity\n",
    "    clf = GridSearchCV(model, parameters, scoring=scoring, verbose=0, cv=n_folds, refit=True, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # perform further searching if metric loss is still significant\n",
    "    new_score = scoring._score_func(clf.predict(X_train), y_train)  # calculate new metric_value\n",
    "    if new_score - initial_score > min_loss:\n",
    "        new_param_dict = {}\n",
    "        for param_name, param_array in parameters.items():\n",
    "            if len(param_array) > 1:\n",
    "                position = param_array.index(clf.best_params_[param_name])\n",
    "                # crete new array of parameters for further research based on best_value's position in array\n",
    "                # if optimal value was the lowest in array - take lower values\n",
    "                new_array = create_new_array(param_name, param_array, position, param_requirments)\n",
    "                # assign new array if it's different than the old one\n",
    "                if (len(new_array) != len(param_array)) or (new_array != param_array).any():\n",
    "                    new_param_dict[param_name] = list(new_array)\n",
    "        if len(new_param_dict) > 0:\n",
    "            find_best_params(model, new_param_dict, X_train, y_train, min_loss, scoring, n_folds, iid, max_fea, initial_score=new_score)\n",
    "\n",
    "    return (clf)\n",
    "\n",
    "\n",
    "# main function- find optimal_parameters for given function\n",
    "def fit_parameters(initial_model, initial_params_dict, X_train, y_train, min_loss, scoring, max_fea, n_folds=5, iid=False):\n",
    "    ### initial check\n",
    "    available_models = ['GradientBoostingRegressor', 'LGBMRegressor']\n",
    "    assert (type(initial_params_dict) is dict)\n",
    "    assert (initial_model.__class__.__name__ in available_models)\n",
    "\n",
    "    model = initial_model\n",
    "    available_params = list(model.get_params().keys())\n",
    "    # domain parameters, which will be used if no parameters provided by user\n",
    "    # 1. n_estimators- should be quite low, in ranparamsge [40-120] (should be fast to checm many parameters, n_estimators will be fine-tuned later)\n",
    "    # if optimal is 20, you might want to try lowering the learning rate to 0.05 and re-run grid search\n",
    "    # learning rate-  0.05-0.2 powinno działać na początku\n",
    "    # for LightGmax_depthBM n_estimators: must be infinite (like 9999999) and use early stopping to auto-tune (otherwise overfitting)\n",
    "    # 2. num leaves- too much will lead to overfitting\n",
    "    # min_samples_split: This should be ~0.5-1% of min_split_gaintotal values.\n",
    "    # min_child_weight:  (sample size / 1000), nevfor p_name, p_array in params_dict.items():ertheless depedns on dataset and loss\n",
    "    # 3. min_samples_leaf : a small value because of imbalanced classes, zrób kombinacje z 5 najlepszymi wartościami min_samples_split\n",
    "    # 4. max_features = ‘sqrt’ : Its a general thumb-rule to start with square root.\n",
    "    # others:param_pair = {'n_estimators': [final_params['n_estimators'] * n], 'learning_rate' : [final_params['learning_rate'] / n]}\n",
    "    # is_unbalance: false (make your own weighting with scale_pos_weight)\n",
    "    # Scale_pos_weight is the ratio of number of negative class to the positive class. Suppose, the dataset has 90 observations of negative class and 10 observations of positive class, then ideal value of scale_pos_Weight should be 9\n",
    "\n",
    "    domain_params_dicts = [{'n_estimators': [30, 50, 70, 100, 150, 200, 300]},\n",
    "                           {'max_depth': [3, 5, 7, 9], 'min_child_weight': [0.001, 0.1, 1, 5, 10, 20], \n",
    "                           'min_samples_split': [2, 5, 10, 20, 30], 'num_leaves': [15, 35, 50, 75, 100, 150]},\n",
    "                           {'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], 'min_samples_leaf': [2, 5, 10, 20, 30],\n",
    "                           'min_child_samples': [2, 7, 15, 25, 45], 'min_split_gain': [0, 0.001, 0.1, 1, 5, 20]},\n",
    "                           {'n_estimators': [30, 50, 70, 100, 150, 200, 300], 'max_features': range(10, max_fea + 3, 3)},\n",
    "                           {'subsample': [i / 10 for i in range(4, 10)], 'colsample_bytree': [i / 10 for i in range(4, 10)], 'feature_fraction': [i / 10 for i in range(4, 10)]},\n",
    "                           {'reg_alpha': [1e-5, 1e-2, 0.1, 1, 25, 100], 'reg_lambda': [1e-5, 1e-2, 0.1, 1, 25, 100]}]\n",
    "\n",
    "    # iterate over parameter anmes from domain_params_dicts, and adjust parameter value from following dictionaries\n",
    "    for params_dict in domain_params_dicts:\n",
    "        params = {}\n",
    "        for p_name, p_array in params_dict.items():\n",
    "            if (p_name in available_params):\n",
    "                params[p_name] = set_initial_params(initial_params_dict, p_name, p_array)\n",
    "\n",
    "        # save new best parameters\n",
    "        best_params = find_best_params(model, params, X_train, y_train, min_loss, scoring, n_folds, iid, max_fea).best_params_\n",
    "        final_params = copy(model.get_params())\n",
    "        model = update_model_params(model, final_params, best_params)\n",
    "\n",
    "    # finally adjust pair (n_estimators, learning_rate)\n",
    "    try:\n",
    "        best_score = None\n",
    "        for n in [1, 2, 4, 8]:\n",
    "            param_pair = {'n_estimators': [final_params['n_estimators'] * n], 'learning_rate': [final_params['learning_rate'] / n]}\n",
    "            clf = GridSearchCV(model, param_pair, scoring=scoring, verbose=0, cv=n_folds, refit=True, n_jobs=-1)\n",
    "            clf.fit(X_train, y_train)\n",
    "            new_score = scoring._score_func(clf.predict(X_train), y_train)  # calculate new metric_value\n",
    "            \n",
    "            # save parameters, if they give better results\n",
    "            best_param_pair = param_pair\n",
    "            if best_score is None:\n",
    "                best_score = new_score\n",
    "            elif scoring.__dict__['_sign'] == 1:  # for score where greater is better\n",
    "                if new_score - best_score >= min_loss:\n",
    "                    best_score = new_score\n",
    "                    best_param_pair = param_pair\n",
    "            elif scoring.__dict__['_sign'] == -1:  # for score where lower is better\n",
    "                if new_score - best_score <= min_loss:\n",
    "                    best_score = new_score\n",
    "                    best_param_pair = param_pair\n",
    "        best_param_pair = convert_dict_of_arrays(best_param_pair)\n",
    "        model = update_model_params(model, final_params, best_param_pair)\n",
    "    except:\n",
    "        pass\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return model, model.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import RandomizedSearchCV'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-374456ec22fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                cv = 5, n_iter = 20, n_jobs=-1)\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mrandm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" Results from Random Search \"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#print(\"The best estimator across ALL searched params:\",randm.best_estimator_)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "model = LGBMRegressor(objective='quantile',boosting_type='gbdt')\n",
    "parameters = {'n_estimators': [10, 100,200, 500, 1000, 2000],\n",
    "              'learning_rate':[0.01,0.02,0.05,0.1],\n",
    "              'max_depth': [1,2,3,4,5,6,7,8],\n",
    "              'min_data_in_leaf': [1,5,10,20,30],\n",
    "              'subsample':[0.5,0.6,0.7,0.8,0.9],\n",
    "              'colsample_bytree':[0.5,0.6,0.7,0.8,0.9],\n",
    "              'alpha':[0.5,0.6,0.7,0.8,0.9],\n",
    "              'reg_alpha':[0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "              'reg_lamda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "randm = RandomizedSearchCV(estimator=model, param_distributions=parameters,\n",
    "                               cv = 5, n_iter = 20, n_jobs=-1)\n",
    "\n",
    "randm.fit(X,y)\n",
    "print(\" Results from Random Search \" )\n",
    "#print(\"The best estimator across ALL searched params:\",randm.best_estimator_)\n",
    "print(\"Trainning Score\",randm.score(X,y))\n",
    "#print(\"Testing Score\",randm.score(X_test_std,Y_test))\n",
    "print(\"The best parameters across ALL searched params:\",randm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
